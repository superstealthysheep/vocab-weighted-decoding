<!DOCTYPE html>
<!-- saved from url=(0014)about:internet -->
<html lang=" en-US"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Weighted Decoding for Vocabulary Acquisition | Fall 2024 CSCI 5541 | University of Minnesota</title>

  <link rel="stylesheet" href="./files/bulma.min.css" />

  <link rel="stylesheet" href="./files/styles.css">
  <link rel="preconnect" href="https://fonts.gstatic.com/">
  <link href="./files/css2" rel="stylesheet">
  <link href="./files/css" rel="stylesheet">


  <base href="." target="_blank"></head>


<body>
  <div>
    <div class="wrapper">
      <h1 style="font-family: &#39;Lato&#39;, sans-serif;">Weighted Decoding for Vocabulary Aquisition</h1>
      <h4 style="font-family: &#39;Lato&#39;, sans-serif; ">NLP Class Project: CSCI 5541, Fall 24 - University of Minnesota</h4>
      <h4 style="font-family: &#39;Lato&#39;, sans-serif; ">Language Learning Mentors (LLMs)</h4>

      <div class="authors-wrapper">
        
        <div class="author-container">
          <div class="author-image">
                        
              <img src="./files/members/william.jpg">
            
            
          </div>
          <p>
                        
            William Walker
            
          </p>
        </div>
        
        <div class="author-container">
          <div class="author-image">
            
            <img src="./files/members/emilie.png">
            
          </div>
          <p>
            
            Emilie Bourget
            
          </p>
        </div>
        
        <div class="author-container">
          <div class="author-image">
            
              <img src="./files/members/philip.jpg">            
            
          </div>
          <p>
              Philip Nguyen
          </p>
        </div>
        
      </div>

      <br/>

      <div class="authors-wrapper">
        <div class="publication-links">
          <!-- Github link -->
          <span class="link-block">
            <a
              href=""
              target="_blank"
              class="external-link button is-normal is-rounded is-dark is-outlined"
            >
            <span>Final Report</span>
            </a>
          </span>
          <span class="link-block">
            <a
              href=""
              target="_blank"
              class="external-link button is-normal is-rounded is-dark is-outlined"
            >
            <span>Code</span>
            </a>
          </span>      
          <span class="link-block">
            <a
              href=""
              target="_blank"
              class="external-link button is-normal is-rounded is-dark is-outlined"
            >
            <span>Model Weights</span>
            </a>
          </span>              
        </div>
      </div>


    </div>
  </div>





  
  


  <div class="wrapper">
    <hr>
    
    <h2 id="abstract">Abstract</h2>


    <!-- <b>One or two sentences on the motivation behind the problem you are solving.</b> -->
    <!-- <p>When beginner-level language learners try to practice conversation with an LLM, a frequent frustration is that the LLM uses a large amount of complicated, advanced vocabulary. We intend to address this problem by creating a conversational chatbot that will preferentially use words familiar to the user and will expand the user's English vocabulary by gradually introducing novel words. Given a list of words that the user is familiar with and a list that is on the frontier of their understanding, at inference time the model will select its wording to prefer familiar words and a small amount of unfamiliar words. -->

    <!-- Our project is to create a conversational chatbot that will expand the user's English vocabulary by gradually introducing novel words. Given a list of words that the user is familiar with and a list that is on the frontier of their understanding, at inference time the model will select its wording to prefer familiar words and a small amount of unfamiliar words. -->

    <!-- <b>One or two sentences describing the approach you took.</b> -->
    <!-- The core of our model will be Llama 3.1 8B. Our problem fits under the larger umbrella of controllable text generation, and the approach that we currently plan to use is to modify the decoder to take a list of target words (e.g. familar words, frontier words) as an auxillary input. Then, when sampling, the decoder will  boost the logits of words* in the familiar and frontier vocab lists. (*Note: since sampling happens on the subword token level, we are thinking about employing a tree search method such as beam search to "look ahead" several tokens into the future and boost the probability of any paths resulting in desired words.) -->


    <b>One or two sentences on the motivation behind the problem you are solving.</b>
    <p>Our project is to create a conversational chatbot that will expand the user's English vocabulary by gradually introducing novel words. Given a list of words that the user is familiar with and a list that is on the frontier of their understanding, at inference time the model will select its wording to prefer familiar words and a small amount of unfamiliar words.</p>

    <b>One or two sentences describing the approach you took.</b>
    <p>The core of our model will be an Llama 3.1 8B. Our problem fits under the larger umbrella of controllable text generation, and the approach that we currently plan to use is to modify the decoder to take a list of target words (e.g. familar words, frontier words) as an auxillary input. Then, when sampling, the decoder will  boost the logits of words* in the familiar and frontier vocab lists. (*Note: since sampling happens on the subword token level, we are thinking about employing a tree search method such as beam search to "look ahead" several tokens into the future and boost the probability of any paths resulting in desired words.)</p>
    
    <b>One or two sentences on the main result you obtained.</b>
    <p>N/A</p>



<hr>

<!-- <h2 id="teaser">Teaser Figure</h2>

<p>A figure that conveys the main idea behind the project or the main application being addressed. </p>

<p class="sys-img"><img src="./files/teaser.png" alt="imgname"></p>


<h3 id="the-timeline-and-the-highlights">Any subsection</h3>

<p>If you need to explain more about your figure</p>

<hr> -->

<h2 id="introduction">Introduction / Background / Motivation</h2>

<p>
<b>What did you try to do? What problem did you try to solve? Articulate your objectives using absolutely no jargon.</b>
</p>
<p>
As language learners, the authors have each attempted to engage in conversations with LLMs to practice our language skills. However, a common problem we've encountered is that the LLM uses lots of vocabulary that is too advanced for us to understand. The ultimate goal of this project is to create a general framework that will address this problem by (note: future features) monitoring the vocabulary used by and understood by the user and (note: current goal) preferentially use words understood by the user, limiting the amount of advanced vocabulary for a better pedagogical experience. For our project, we're limiting our scope to the English language since we all understand English and think it will serve as a good initial prototyping and proving ground.
</p>

<p>
<b>How is it done today, and what are the limits of current practice?</b>
</p>
<p>
Based on a brief literature survey, there seems to not be much work directly done on the problem of limiting vocab for language learners. We have found writings on constrained decoding and looser ways to control the generation of LLMs, and we also intend to research further in the educational/HCI literature for other projects that seek to assist language (and especially vocabulary) aquisition.
<p>

<p>
<b>Who cares? If you are successful, what difference will it make?</b>
</p>
<p>
This project would have a direct use for the authors (and other language learners) because it would allow for more effective pedagogical conversations with LLMs. This would potentially have general applications for all language learners who wish to practice conversation with LLMs but who are overwhelmed by a large amount of advanced vocabulary used by the LLM. The authors currently imagine that the user would likely be people learning a second language, but perhaps this technique could even find use in early acquisition of first languages in children (perhaps).
</p>

<hr>

<h2 id="approach">Approach</h2>

<p>
<b>What did you do exactly? How did you solve the problem? Why did you think it would be successful? Is anything new in your approach?</b>
</p>

<p>
  The core of our model will be an Llama 3.1 8B. Our problem fits under the larger umbrella of controllable text generation, and the approach that we currently plan to use is to modify the decoder to take a list of target words (e.g. familar words, frontier words) as an auxillary input. Then, when sampling, the decoder will  boost the logits of words* in the familiar and frontier vocab lists. (*Note: since sampling happens on the subword token level, we are thinking about employing a tree search method such as beam search to "look ahead" several tokens into the future and boost the probability of any paths resulting in desired words.) This vocab-list-based softly-constrained decoder seems novel in the literature based on our cursory investigations.
</p>

<p>
<b>What problems did you anticipate? What problems did you encounter? Did the very first thing you tried work?</b>
</p>

<p>
Getting things running on MSI may be a challenge, and we're still at time of writing figuring out exactly how we're going to quantitatively evaluate our model. Another worry is that direct decoding-time interference may be too "local" of a modification to make, so maybe this method would not perform well in the case of languages with long-range linguistic structures (seperable verb/complement pairs like in German (and English) come to mind.)
</p>

<hr>
    
<h2 id="results">Results</h2>
<p>
<b>How did you measure success? What experiments were used? What were the results, both quantitative and qualitative? Did you succeed? Did you fail? Why?</b>
</p>
<p>
We still need to figure our evaluation metrics out. We'll look at educational/HCI literature and perhaps end up defining some bespoke evaluation metric, though considering our time limitations, it will likely need to be quite simple to implement.
<!-- </p>
<table>
  <thead>
    <tr>
      <th style="text-align: center"><strong>Experiment</strong></th>
      <th style="text-align: center">1</th>
      <th style="text-align: center">2</th>
      <th style="text-align: center">3</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><strong>Sentence</strong></td>
      <td style="text-align: center">Example 1</td>
      <td style="text-align: center">Example 2</td>
      <td style="text-align: center">Example 3</td>
    </tr>
    <tr>
      <td style="text-align: center"><strong>Errors</strong></td>
      <td style="text-align: center">error A, error B, error C</td>
      <td style="text-align: center">error C</td>
      <td style="text-align: center">error B</td>
    </tr>
  </tbody>
  <caption>Table 1. This is Table 1's caption</caption>
</table>
<br>
<div style="text-align: center;">
<img style="height: 300px;" alt="" src="./files/results.png">
</div> -->
<br><br>

<hr>



<!-- <h2 id="conclusion">Conclusion and Future Work</h2>
<p>

  How easily are your results able to be reproduced by others?
  Did your dataset or annotation affect other people's choice of research or development projects to undertake?
  Does your work have potential harm or risk to our society? What kinds? If so, how can you address them?
  What limitations does your model have? How can you extend your work for future research?</p>

<hr> -->


  </div>
  


</body></html>
